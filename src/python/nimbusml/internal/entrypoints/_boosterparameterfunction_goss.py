# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
goss
"""

import numbers

from ..utils.entrypoints import Component
from ..utils.utils import try_set


def goss(
        top_rate=0.2,
        other_rate=0.1,
        unbalanced_sets=False,
        min_split_gain=0.0,
        max_depth=0,
        min_child_weight=0.1,
        subsample_freq=0,
        subsample=1.0,
        feature_fraction=1.0,
        reg_lambda=0.01,
        reg_alpha=0.0,
        scale_pos_weight=1.0,
        **params):
    """
    **Description**
        Gradient-based One-Side Sampling.

    :param top_rate: Retain ratio for large gradient instances.
        (settings).
    :param other_rate: Retain ratio for small gradient instances.
        (settings).
    :param unbalanced_sets: Use for binary classification when
        classes are not balanced. (settings).
    :param min_split_gain: Minimum loss reduction required to make a
        further partition on a leaf node of the tree. the larger, the
        more conservative the algorithm will be. (settings).
    :param max_depth: Maximum depth of a tree. 0 means no limit.
        However, tree still grows by best-first. (settings).
    :param min_child_weight: Minimum sum of instance weight(hessian)
        needed in a child. If the tree partition step results in a
        leaf node with the sum of instance weight less than
        min_child_weight, then the building process will give up
        further partitioning. In linear regression mode, this simply
        corresponds to minimum number of instances needed to be in
        each node. The larger, the more conservative the algorithm
        will be. (settings).
    :param subsample_freq: Subsample frequency. 0 means no subsample.
        If subsampleFreq > 0, it will use a subset(ratio=subsample)
        to train. And the subset will be updated on every Subsample
        iteratinos. (settings).
    :param subsample: Subsample ratio of the training instance.
        Setting it to 0.5 means that LightGBM randomly collected half
        of the data instances to grow trees and this will prevent
        overfitting. Range: (0,1]. (settings).
    :param feature_fraction: Subsample ratio of columns when
        constructing each tree. Range: (0,1]. (settings).
    :param reg_lambda: L2 regularization term on weights, increasing
        this value will make model more conservative. (settings).
    :param reg_alpha: L1 regularization term on weights, increase
        this value will make model more conservative. (settings).
    :param scale_pos_weight: Control the balance of positive and
        negative weights, useful for unbalanced classes. A typical
        value to consider: sum(negative cases) / sum(positive cases).
        (settings).
    """

    entrypoint_name = 'goss'
    settings = {}

    if top_rate is not None:
        settings['TopRate'] = try_set(
            obj=top_rate,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Inf': 0.0,
                'Max': 1.0})
    if other_rate is not None:
        settings['OtherRate'] = try_set(
            obj=other_rate,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Inf': 0.0,
                'Max': 1.0})
    if unbalanced_sets is not None:
        settings['UnbalancedSets'] = try_set(
            obj=unbalanced_sets, none_acceptable=True, is_of_type=bool)
    if min_split_gain is not None:
        settings['MinSplitGain'] = try_set(
            obj=min_split_gain,
            none_acceptable=True,
            is_of_type=numbers.Real, valid_range={'Min': 0.0})
    if max_depth is not None:
        settings['MaxDepth'] = try_set(
            obj=max_depth,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Max': 2147483647,
                'Min': 0})
    if min_child_weight is not None:
        settings['MinChildWeight'] = try_set(
            obj=min_child_weight,
            none_acceptable=True,
            is_of_type=numbers.Real, valid_range={'Min': 0.0})
    if subsample_freq is not None:
        settings['SubsampleFreq'] = try_set(
            obj=subsample_freq,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Max': 2147483647,
                'Min': 0})
    if subsample is not None:
        settings['Subsample'] = try_set(
            obj=subsample,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Inf': 0.0,
                'Max': 1.0})
    if feature_fraction is not None:
        settings['FeatureFraction'] = try_set(
            obj=feature_fraction,
            none_acceptable=True,
            is_of_type=numbers.Real,
            valid_range={
                'Inf': 0.0,
                'Max': 1.0})
    if reg_lambda is not None:
        settings['RegLambda'] = try_set(
            obj=reg_lambda,
            none_acceptable=True,
            is_of_type=numbers.Real, valid_range={'Min': 0.0})
    if reg_alpha is not None:
        settings['RegAlpha'] = try_set(
            obj=reg_alpha,
            none_acceptable=True,
            is_of_type=numbers.Real, valid_range={'Min': 0.0})
    if scale_pos_weight is not None:
        settings['ScalePosWeight'] = try_set(
            obj=scale_pos_weight,
            none_acceptable=True,
            is_of_type=numbers.Real)

    component = Component(
        name=entrypoint_name,
        settings=settings,
        kind='BoosterParameterFunction')
    return component
