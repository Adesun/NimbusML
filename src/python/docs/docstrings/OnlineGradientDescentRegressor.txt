    """

    Train a stochastic gradient descent model.

    .. remarks::
        Stochastic gradient descent uses a simple yet efficient iterative
        technique to fit model
        coefficients using error gradients for convex loss functions (see
        `Stochastic_gradient_descent
        <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>`_).

        The ``OnlineGradientDescentRegressor`` implements the standard (non-
        batch) SGD, with a
        choice of loss functions, and an option to update the weight vector
        using the `average` of
        the vectors seen over time (``averaged`` argument is set to **True**
        by default).


        **Reference**
    
            `Stochastic_gradient_descent
            <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>`_
    

    :param feature: see `Columns </nimbusml/concepts/columns>`_.

    :param label: see `Columns </nimbusml/concepts/columns>`_.

    :param columns: see `Columns </nimbusml/concepts/columns>`_.

    :param normalize: Specifies the type of automatic normalization used:

        * ``"Auto"``: if normalization is needed, it is performed
          automatically. This is the default choice.
        * ``"No"``: no normalization is performed.
        * ``"Yes"``: normalization is performed.
        * ``"Warn"``: if normalization is needed, a warning
          message is displayed, but normalization is not performed.

        Normalization rescales disparate data ranges to a standard scale.
        Feature
        scaling insures the distances between data points are proportional
        and
        enables various optimization methods such as gradient descent to
        converge
        much faster. If normalization is performed, a ``MaxMin`` normalizer
        is
        used. It normalizes values in an interval [a, b] where ``-1 <= a <=
        0``
        and ``0 <= b <= 1`` and ``b - a = 1``. This normalizer preserves
        sparsity by mapping zero to zero.

    :param recency_gain: Extra weight given to more recent updates
        (`do_lazy_updates`` must be **False**).

    :param recency_gain_multi: Whether Recency Gain is multiplicative vs.
        additive (`do_lazy_updates`` must be **False**).

    .. seealso::
        :py:func:`FastLinearRegressor
        <nimbusml.linear_model.FastLinearRegressor>`,
        :py:func:`LightGbmRegressor <nimbusml.ensemble.LightGbmRegressor>`,
        :py:func:`FastForestRegressor <nimbusml.ensemble.FastForestRegressor>`,
        :py:func:`FastTreesRegressor <nimbusml.ensemble.FastTreesRegressor>`,
        :py:func:`GamRegressor <nimbusml.ensemble.GamRegressor>`.

    .. index:: models, stochastic, online, gradient, descent

    Example:
       .. literalinclude:: /../nimbusml/examples/OnlineGradientDescentRegressor.py
              :language: python
    """