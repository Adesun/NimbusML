"""
Some of the trainers accept a loss parameter that will be used for
training. It is also known as loss function, objective function, or
optimization score function.

.. remarks::
	Losses can be specified either as a string or a loss object. When
	loss is specified as one of these strings, the default values are
	used for the loss parameters. To change the default parameters, a
	loss object should be used, as seen in examples below.

	Each trainer supports only a subset of the losses mentioned above.
	To get the supported losses and the default loss, please refer to
	the documentation page for the specific trainer.

	The `Smoothed hinge loss
	<https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
	for classification. Its string name is ``'smoothed_hinge'``.

	It can be used for :py:class:`AveragedPerceptronBinaryClassifier
	<nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
	:py:class:`FastLinearBinaryClassifier
	<nimbusml.linear_model.FastLinearBinaryClassifier>`,
	:py:class:`FastLinearClassifier
	<nimbusml.linear_model.FastLinearClassifier>`,
	:py:class:`SgdBinaryClassifier
	<nimbusml.linear_model.SgdBinaryClassifier>`.

:param smoothing_const: Smoothing constant

.. seealso::
	:py:class:`Exp <nimbusml.loss.Exp>`
	:py:class:`Log <nimbusml.loss.Log>`
	:py:class:`Hinge <nimbusml.loss.Hinge>`
	`API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

Example:
	.. literalinclude:: /../nimbusml/examples/SmoothedHinge.py
		:language: python


.. index:: loss
"""