"""
Some of the trainers accept a loss parameter that will be used for
training. It is also known as loss function, objective function, or
optimization score function.


.. remarks::
	Losses can be specified either as a string or a loss object. When
	loss is specified as one of these strings, the default values are
	used for the loss parameters. To change the default parameters, a
	loss object should be used, as seen in examples below.

	Each trainer supports only a subset of the losses mentioned above.
	To get the supported losses and the default loss, please refer to
	the documentation page for the specific trainer.

	The `Exponential loss
	<https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
	for classification. Compared to :py:class:`Hinge
	<nimbusml.loss.Hinge>`, it penalizes more on the wrong prediction and
	has larger gradients. Its string name is ``'exp'``.

	It can be used for :py:class:`AveragedPerceptronBinaryClassifier
	<nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
	:py:class:`SgdBinaryClassifier
	<nimbusml.linear_model.SgdBinaryClassifier>`.

:param beta: Dilation

.. seealso::
	:py:class:`Log <nimbusml.loss.Log>`
	:py:class:`Hinge <nimbusml.loss.Hinge>`
	:py:class:`SmoothedHinge <nimbusml.loss.SmoothedHinge>`
	`API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

Example:
	.. literalinclude:: /../nimbusml/examples/Exp.py
		:language: python

.. index:: loss
"""